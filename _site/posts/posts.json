[
  {
    "path": "posts/2021-07-05-assignment/",
    "title": "Assignment",
    "description": "This post is built for Assignment of ISSS608 Visual Analytics and Application.",
    "author": [
      {
        "name": "LI Yuhong",
        "url": {}
      }
    ],
    "date": "2021-07-05",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Overview\r\n1.1 Background\r\n1.2 Objective\r\n\r\n2. Literature Review\r\n3. Installation and load of R packages\r\n4. Data Wrangling and Extraction\r\n4.1 Data Import and View\r\n4.2 Data Wrangling and Extraction\r\n\r\n5. The Most Popular Locations\r\n5.1 Identification of Popular Locations\r\n5.2 Identification of Popular Periods\r\n\r\n6. Owner Inference\r\n6.1 Plot GPS Path and Stop-by Points for Each Car\r\nCarID|Path Plots|CarID|Path Plots\r\n6.2 Match Owners for Credit Card and Loyalty Card\r\n6.3 Uncertainties\r\n\r\n7. Anomalies and Suspicious Activity\r\n7.1 Evidence\r\n7.2 Location Identification\r\n\r\n8. Conclusion\r\n\r\n1. Overview\r\n1.1 Background\r\nThis assignment topic is based on Mini-Challenge 2 of VAST Challenge 2021, and there is background introduction of VAST Challenge 2021.\r\nIn the roughly twenty years that Tethys-based GAStech has been operating a natural gas production site in the island country of Kronos, it has produced remarkable profits and developed strong relationships with the government of Kronos. However, GAStech has not been as successful in demonstrating environmental stewardship.\r\nIn January, 2014, the leaders of GAStech are celebrating their new-found fortune as a result of the initial public offering of their very successful company. In the midst of this celebration, several employees of GAStech go missing. An organization known as the Protectors of Kronos (POK) is suspected in the disappearance, but things may not be what they seem.\r\n1.2 Objective\r\nThe data used in this research is the movement and tracking data of employees. GAStech provides many of their employees with company cars for their personal and professional use, but unbeknownst to the employees, the cars are equipped with GPS tracking devices.\r\nBased on the given tracking data for the two weeks leading up to the disappearance, as well as credit card transactions and loyalty card usage data, we aim to use appropriate visually driven data analysis techniques to complete two objectives:\r\nIdentify anomalies and suspicious behaviors.\r\nIdentify the owners of each credit and loyalty card .\r\n2. Literature Review\r\nData visualization is the practice of translating information into a visual context, such as a map or graph, to make data easier for the human brain to understand and pull insights from. The main goal of data visualization is to make it easier to identify patterns, trends and outliers in large data sets. It provides a quick and effective way to communicate information in a universal manner using visual information.\r\nIn this research, the two main data visualization methods used to attain research goals and answer questions are graphs and maps. Graphs include stable graphs and interactive graphs and the main R packages used are ggplot and plotly. The ggplot package is the most popular data visualization package in the R community. It was created by Hadley Wickham in 2005. It was implemented based on Leland Wilkinson’s Grammar of Graphics — a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. While using ggplot2, we provide the data, call specific function, map our desired variables to aesthetics, define graphical arguments.\r\n3. Installation and load of R packages\r\nThe code chunks below are used to install and load the packages in R.\r\n\r\n\r\npackages = c(\"tidyverse\",\"tidyr\",\"tidyverse\",\"dplyr\",\"sp\",\"raster\",\"sf\",\r\n             \"vctrs\",\"clock\",\"tmap\",\"rgdal\",\"readr\",\"ggplot2\",\"plotly\",\"tmap\",\"gganimate\",\"av\",\"gifski\",\r\n             \"igraph\",\"tidygraph\",\"ggraph\",\"visNetwork\",\"lubridate\",\"DT\")\r\nfor (p in packages){\r\n  if(!require(p, character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p, character.only = T)\r\n}\r\n\r\n\r\n\r\n4. Data Wrangling and Extraction\r\n4.1 Data Import and View\r\nThe data was imported by using read.csv().\r\n\r\n\r\ncarassign <- read_csv(\"./MC2/car-assignments.csv\")\r\n\r\ncreditcard <- read.csv(\"./MC2/cc_data.csv\")\r\n\r\ngps <- read_csv(\"./MC2/gps.csv\")\r\n\r\nloyaltycard <- read.csv(\"./MC2/loyalty_data.csv\")\r\n\r\nAbila_st <- st_read(dsn = \"MC2/Geospatial\",\r\n                    layer = \"Abila\")\r\n\r\n\r\nReading layer `Abila' from data source \r\n  `D:\\liyuhong0110\\BlogFile\\_posts\\2021-07-05-assignment\\MC2\\Geospatial' \r\n  using driver `ESRI Shapefile'\r\nSimple feature collection with 3290 features and 9 fields\r\nGeometry type: LINESTRING\r\nDimension:     XY\r\nBounding box:  xmin: 24.82401 ymin: 36.04502 xmax: 24.90997 ymax: 36.09492\r\nGeodetic CRS:  WGS 84\r\n\r\nChange the data type of MC2-tourist.jpg to tif by save as. (Figure 1)\r\nFigure 1\r\nView the data by the following coding.\r\n\r\n\r\nhead(carassign)\r\n\r\n\r\n# A tibble: 6 x 5\r\n  LastName FirstName CarID CurrentEmploymentType CurrentEmploymentTit~\r\n  <chr>    <chr>     <dbl> <chr>                 <chr>                \r\n1 Calixto  Nils          1 Information Technolo~ IT Helpdesk          \r\n2 Azada    Lars          2 Engineering           Engineer             \r\n3 Balas    Felix         3 Engineering           Engineer             \r\n4 Barranco Ingrid        4 Executive             SVP/CFO              \r\n5 Baza     Isak          5 Information Technolo~ IT Technician        \r\n6 Bergen   Linnea        6 Information Technolo~ IT Group Manager     \r\n\r\nhead(creditcard)\r\n\r\n\r\n         timestamp            location price last4ccnum\r\n1 01/06/2014 07:28 Brew've Been Served 11.34       4795\r\n2 01/06/2014 07:34    Hallowed Grounds 52.22       7108\r\n3 01/06/2014 07:35 Brew've Been Served  8.33       6816\r\n4 01/06/2014 07:36    Hallowed Grounds 16.72       9617\r\n5 01/06/2014 07:37 Brew've Been Served  4.24       7384\r\n6 01/06/2014 07:38 Brew've Been Served  4.17       5368\r\n\r\nhead(gps)\r\n\r\n\r\n# A tibble: 6 x 4\r\n  Timestamp           id   lat  long\r\n  <chr>            <dbl> <dbl> <dbl>\r\n1 01/06/2014 06:28    35  36.1  24.9\r\n2 01/06/2014 06:28    35  36.1  24.9\r\n3 01/06/2014 06:28    35  36.1  24.9\r\n4 01/06/2014 06:28    35  36.1  24.9\r\n5 01/06/2014 06:28    35  36.1  24.9\r\n6 01/06/2014 06:28    35  36.1  24.9\r\n\r\nhead(loyaltycard)\r\n\r\n\r\n   timestamp            location price loyaltynum\r\n1 01/06/2014 Brew've Been Served  4.17      L2247\r\n2 01/06/2014 Brew've Been Served   9.6      L9406\r\n3 01/06/2014    Hallowed Grounds 16.53      L8328\r\n4 01/06/2014        Coffee Shack 11.51      L6417\r\n5 01/06/2014    Hallowed Grounds 12.93      L1107\r\n6 01/06/2014 Brew've Been Served  4.27      L4034\r\n\r\nThe overview of data are shown in Table 1.\r\nTable 1\r\nS/N\r\nName of Data\r\nNumber of Observations\r\nVariables\r\n1\r\ncarassign\r\n44\r\nLastName, FirstName, CarID, CurrentEmploymentType, CurrentEmploymentTitle\r\n2\r\ncreditcard\r\n1490\r\ntimestamp, location, price, last4ccnum\r\n3\r\ngps\r\n685,169\r\nTimestamp, id, lat, long\r\n4\r\nloyaltycard\r\n1392\r\ntimestamp, location, price, loyaltynum\r\n4.2 Data Wrangling and Extraction\r\n4.2.1 Correct Data Type\r\nThe columns of “timestamp” should be Date data type instead of character, so we change the data type as the following codes.\r\n\r\n\r\n# Change data type of columns \"timestamp\"\r\ncreditcard$timestamp <- date_time_parse(creditcard$timestamp,\r\n                                 zone=\"\",\r\n                                 format=\"%m/%d/%Y %H:%M\")\r\n\r\nloyaltycard$timestamp <- date_time_parse(loyaltycard$timestamp,\r\n                                 zone=\"\",\r\n                                 format=\"%m/%d/%Y\")\r\n\r\ngps$Timestamp <- date_time_parse(gps$Timestamp,\r\n                                 zone=\"\",\r\n                                 format=\"%m/%d/%Y %H:%M\")\r\n\r\n\r\n\r\n4.2.2 Adjust Incorrect Columns\r\nThere are some incorrect columns shown in Figure 2 in the dataset of creditcard and loyaltycard.\r\nFigure 2\r\nFor loyaltycard dataset, we correct this problem by the following codes and get the dataset of loyaltycard_final dataset which will be used in the following analysis.\r\n\r\n\r\n# Build the wrong loyaltycard dataset\r\nwrongloyalty <- loyaltycard %>%\r\n  filter(loyaltynum==\"\")\r\nwrongloyalty <- wrongloyalty[,-4]\r\nnames(wrongloyalty)[3] <-\"loyaltynum\"\r\nwrongloyalty <- wrongloyalty %>%\r\n  separate(location,into = c(\"location\",\"price\"),sep =\"\\\\?\",convert = TRUE)\r\nhead(wrongloyalty)\r\n\r\n\r\n   timestamp       location price loyaltynum\r\n1 2014-01-06 Katerina’s Caf 33.54      L6110\r\n2 2014-01-06 Katerina’s Caf 38.65      L6110\r\n3 2014-01-06 Katerina’s Caf 26.46      L8328\r\n4 2014-01-06 Katerina’s Caf 28.00      L6267\r\n5 2014-01-06 Katerina’s Caf 26.51      L9406\r\n6 2014-01-07 Katerina’s Caf 37.44      L2343\r\n\r\n# Remove Null rows\r\nloyaltycard <- loyaltycard %>%\r\n  filter(loyaltynum!=\"\")\r\n\r\n# Change the data type of \"price\" column\r\nloyaltycard$price <- as.numeric(loyaltycard$price)\r\nclass(loyaltycard$price)\r\n\r\n\r\n[1] \"numeric\"\r\n\r\n# Combine wrongloyaltycard and loyaltycard dataset to build final loyalty card dataset\r\nloyaltycard_final <- rbind(loyaltycard,wrongloyalty)\r\n\r\n\r\n\r\nAfter completing the same actions in the creditcard dataset as following, we got the dataset of creditcard_final dadtaset.\r\n\r\n\r\n# Build the wrong creditcard dataset\r\nwrongcredit <- creditcard %>%\r\n  filter(is.na(last4ccnum))\r\nwrongcredit <- wrongcredit[,-4]\r\nnames(wrongcredit)[3] <-\"last4ccnum\"\r\nwrongcredit <- wrongcredit %>%\r\n  separate(location,into = c(\"location\",\"price\"),sep =\"\\\\?\",convert = TRUE)\r\nhead(wrongcredit) \r\n\r\n\r\n            timestamp       location price last4ccnum\r\n1 2014-01-06 12:56:00 Katerina’s Caf 13.68       8332\r\n2 2014-01-06 13:28:00 Katerina’s Caf 33.54       8411\r\n3 2014-01-06 13:46:00 Katerina’s Caf 18.56       6899\r\n4 2014-01-06 13:50:00 Katerina’s Caf 13.59       1874\r\n5 2014-01-06 13:50:00 Katerina’s Caf 32.64       9617\r\n6 2014-01-06 13:53:00 Katerina’s Caf 36.95       2142\r\n\r\n# Remove Null rows\r\ncreditcard <- creditcard %>%\r\n  filter(last4ccnum!=\"NA\")\r\n\r\n# Combine wrongcredit and creditcard dataset to build final credit card dataset\r\ncreditcard_final <- rbind(creditcard,wrongcredit)\r\n\r\n\r\n\r\nFirstName and LastName columns can be combined to build a new column in the carassign dataset, and then a new dataset called carassign_final was built.\r\n\r\n\r\n# Combine FirstName and LastName columns\r\ncarassign_final <- carassign %>% \r\n  unite(Name,c(\"FirstName\",\"LastName\"), sep = \" \")\r\n\r\n\r\n\r\n4.2.3 Check Missing Values\r\nThen we check the missing values and view the wrangled dataset.\r\n\r\n\r\n# Identify missing values\r\nwhich(rowSums(is.na(loyaltycard_final))==TRUE)\r\n\r\n\r\ninteger(0)\r\n\r\nwhich(rowSums(is.na(creditcard_final))==TRUE)\r\n\r\n\r\ninteger(0)\r\n\r\nwhich(rowSums(is.na(carassign_final))==TRUE)\r\n\r\n\r\n[1] 36 37 38 39 40 41 42 43 44\r\n\r\nwhich(rowSums(is.na(gps))==TRUE)\r\n\r\n\r\ninteger(0)\r\n\r\n# Check the dataset\r\nhead(loyaltycard_final)\r\n\r\n\r\n   timestamp            location price loyaltynum\r\n1 2014-01-06 Brew've Been Served  4.17      L2247\r\n2 2014-01-06 Brew've Been Served  9.60      L9406\r\n3 2014-01-06    Hallowed Grounds 16.53      L8328\r\n4 2014-01-06        Coffee Shack 11.51      L6417\r\n5 2014-01-06    Hallowed Grounds 12.93      L1107\r\n6 2014-01-06 Brew've Been Served  4.27      L4034\r\n\r\nhead(creditcard_final)\r\n\r\n\r\n            timestamp            location price last4ccnum\r\n1 2014-01-06 07:28:00 Brew've Been Served 11.34       4795\r\n2 2014-01-06 07:34:00    Hallowed Grounds 52.22       7108\r\n3 2014-01-06 07:35:00 Brew've Been Served  8.33       6816\r\n4 2014-01-06 07:36:00    Hallowed Grounds 16.72       9617\r\n5 2014-01-06 07:37:00 Brew've Been Served  4.24       7384\r\n6 2014-01-06 07:38:00 Brew've Been Served  4.17       5368\r\n\r\nhead(carassign_final)\r\n\r\n\r\n# A tibble: 6 x 4\r\n  Name            CarID CurrentEmploymentType  CurrentEmploymentTitle\r\n  <chr>           <dbl> <chr>                  <chr>                 \r\n1 Nils Calixto        1 Information Technology IT Helpdesk           \r\n2 Lars Azada          2 Engineering            Engineer              \r\n3 Felix Balas         3 Engineering            Engineer              \r\n4 Ingrid Barranco     4 Executive              SVP/CFO               \r\n5 Isak Baza           5 Information Technology IT Technician         \r\n6 Linnea Bergen       6 Information Technology IT Group Manager      \r\n\r\nhead(gps)\r\n\r\n\r\n# A tibble: 6 x 4\r\n  Timestamp              id   lat  long\r\n  <dttm>              <dbl> <dbl> <dbl>\r\n1 2014-01-06 06:28:00    35  36.1  24.9\r\n2 2014-01-06 06:28:00    35  36.1  24.9\r\n3 2014-01-06 06:28:00    35  36.1  24.9\r\n4 2014-01-06 06:28:00    35  36.1  24.9\r\n5 2014-01-06 06:28:00    35  36.1  24.9\r\n6 2014-01-06 06:28:00    35  36.1  24.9\r\n\r\nWe can see that there are missing values (Figure 3) in rows from 36 to 44 in carassign_final dataset. It means that cardID is lack for truck drivers.\r\nFigure 3\r\nBecause the trucks cannot be used for personal business and we didn’t have the car ID for them, we cannot find the tracks and behaviors for these employees. Hence, we delete these rows by the following codes.\r\n\r\n\r\n# Filter the rows without NA\r\ncarassign_final <- carassign_final %>% \r\n  filter(CarID!=\"\")\r\n\r\n\r\n\r\n4.2.4 Data Extraction\r\nAfter observing we find that only car ID from 1 to 35 will be used, so car ID included other number Figure 4 will be excluded from the analysis of gps dataset.\r\nFigure 4\r\n5. The Most Popular Locations\r\n5.1 Identification of Popular Locations\r\nThere are two dataset can be used to identify the popular locations, and after obversing the relationship of two dataset we find that there is some purchase was recorded in both dataset due to the same purchase time and purchase price. Hence, we will be based on loyaltycard_final and creditcard_final respectively.\r\n5.1.1 Based on Loyalty Card Recording\r\nTo identify the the popular locations based on loyalty card dataset, we use the following steps.\r\n\r\n\r\n# Calculate the number of locations appeared based on loyalty card\r\nlocation_num_loyaltycard <- loyaltycard_final %>% \r\n  group_by(location) %>% \r\n  summarise(num_loyalty=n()) %>% \r\n  arrange(desc(num_loyalty))\r\n\r\n# Plot the number of locations appeared based on loyalty card\r\np1 <- plot_ly(data = location_num_loyaltycard,\r\n              x = ~location,y = ~num_loyalty,\r\n              type=\"bar\",\r\n              text = ~paste(\"Location:\", location,\r\n                      \"<br>Frequency:\", num_loyalty)) %>% \r\n  layout(yaxis = list(title = 'Frequency'),\r\n         xaxis = list(title = 'Location',\r\n                      categoryorder = \"array\",\r\n                      categoryarray = ~num_loyalty),\r\n         title = 'The Frequency of Each Location Based on Loyalty Card')\r\np1\r\n\r\n\r\npreserve6b12c8c0744a2e87\r\n\r\nThe graph shows that the five most popular locations is: Katerina’s Caf, Hippokampos, Guy’s Gyros, Brew’ve Been Served, and Hallowed Grounds (Figure 5).\r\n\r\nFigure 5\r\n5.1.2 Based on Credit Card Recording\r\nTo identify the the popular locations based on credit card dataset, we use the following steps.\r\n\r\n\r\n# Calculate the number of locations appeared based on credit card\r\nlocation_num_creidtcard <- creditcard_final %>% \r\n  group_by(location) %>% \r\n  summarise(num_credit=n()) %>% \r\n  arrange(desc(num_credit))\r\n\r\n# Plot the number of locations appeared based on credit card\r\np2 <- plot_ly(data = location_num_creidtcard,\r\n              x = ~location,y = ~num_credit,\r\n              type=\"bar\",\r\n              text = ~paste(\"Location:\", location,\r\n                      \"<br>Frequency:\", num_credit)) %>% \r\n  layout(yaxis = list(title = 'Frequency of happened purchase'),\r\n         xaxis = list(title = 'Location',\r\n                      categoryorder = \"array\",\r\n                      categoryarray = ~num_credit),\r\n         title = 'The Frequency of Each Location Based on Credit Card')\r\np2\r\n\r\n\r\npreservebf6dfa25bd9e4eff\r\n\r\nThe graph shows that the five most popular locations is: Katerina’s Caf, Hippokampos, Guy’s Gyros, Brew’ve Been Served, and Hallowed Grounds (Figure 6), which is the same as the result based on loyalty card dataset.\r\n\r\nFigure 6\r\n5.2 Identification of Popular Periods\r\nThe hour and minute was recorded in Timestamp columns in creditcard dataset, but not in loyalty dataset. Hence, we will figure out the popular days based on loyalty dataset, and find the pupular moment based on creditcard dataset.\r\n5.2.1 Based on Loyalty Card Recording\r\nWrite the following codes to draw the graph for the five most popular locations.\r\n\r\n\r\n# Build new dataset for the five most popular locations\r\nloyalty_day <- loyaltycard_final %>% \r\n  filter(location==c(\"Katerina’s Caf\", \"Hippokampos\", \"Guy's Gyros\", \r\n                     \"Brew've Been Served\", \"Hallowed Grounds\")) \r\n\r\n# Build a new column for day and change the data type\r\nloyalty_day$day <- as.numeric(get_day(loyalty_day$timestamp))\r\n\r\n# Wrangle the dataset for the frequency of purchase for every day\r\nloyalty_day_num <- loyalty_day %>% \r\n  group_by(day) %>% \r\n  summarise(frequency=n())\r\n\r\n# Draw the graph\r\np3 <- plot_ly(data = loyalty_day_num,\r\n              x = ~day, \r\n              y = ~frequency, \r\n              type = 'scatter', \r\n              mode = 'lines',\r\n              text = ~paste(\"Day:\", day,\r\n                      \"<br>Frequency:\", frequency),\r\n              name=\"Trend\") %>% \r\n  layout(yaxis = list(title = 'Frequency'),\r\n         xaxis = list(title = 'Day'),\r\n         title = \"Frequency of Loyalty Card Purchase for Five Most Pupular Locations\") %>% \r\n  add_trace(mode = 'markers',\r\n            name=\"Detail\")\r\n\r\np3\r\n\r\n\r\npreservee583abef185bd178\r\n\r\nThe line graph shows that 2014/1/6, 2014/1/16 and 2014/1/17 are the most popular days for the five most popular locations due to the peak that appeared in these dates.\r\n5.2.2 Based on Credit Card Recording\r\nWrite the following codes to draw the 2D Histograms graph for the 20 most popular locations.\r\n\r\n\r\n# Build new dataset for the five most popular locations\r\ncredit_hour <- creditcard_final %>% \r\n  filter(location==c(\"Katerina’s Caf\", \"Hippokampos\", \"Guy's Gyros\", \r\n                     \"Brew've Been Served\", \"Hallowed Grounds\")) \r\n\r\n# Build a new column for day and change the data type\r\ncredit_hour$hour <- as.numeric(get_hour(credit_hour$timestamp))\r\n\r\n# Wrangle the dataset for the frequency of purchase for every day\r\ncredit_hour_num <- credit_hour %>% \r\n  group_by(location,hour) %>% \r\n  summarise(frequency=n())\r\n\r\n# Draw the graph\r\np4 <- ggplot(data=credit_hour_num,\r\n             aes(x=location,y=hour,fill=frequency))+\r\n  geom_tile()+\r\n  scale_y_continuous(limits = c(0,24),\r\n                     breaks = c(0,2,4,6,8,10,12,14,16,18,20,22,24))+\r\n  scale_fill_gradient2(low=\"blue\",\r\n                       high=\"red\")+\r\n  labs(x=\"Location\",\r\n       y=\"Hour\",\r\n       title=\"Frequency of Credit Card Purchase for Five Most Popular Locations\")+\r\n  theme(plot.title=element_text(hjust=0.5))\r\np4\r\n\r\n\r\n\r\n\r\nBased on the above graph, we can find that 7:00-8:00 is popular for Brew’ve Been Served and Hallowed Grounds, and 13:00-14:00 and 19:00-20:00 is popular for Katerina’s Caf, Hippokampos, Guy’s Gyros.\r\n5.2.3 Anomalies\r\nPopular and Important Coffee Shops A large part of the most popular locations for GAStech employees are coffee shops. For example, three locations, Katerina’s Caf, Brew’ve Been Served, and Hallowed Grounds in the five most popular locations are coffee shops.\r\nBased on the frequency of purchase, we knew that there are a cycle of low frequency of purchase for the five most popular locations, and the time interval was 5 days. We can speculate that 2014/1/11, 2014/1/12, 2014/1/18 and 2014/1/19 are weekends. And after checking the calender, we can confirm our guess. Hence, we can conclude that these locations were the important locations for GAStech employees to break, have meals and work in weekdays, and employees went to these location less in weekends. The coffee shops provided suitable and comfortable environment for the GAStech employees who leaf companies.\r\nFigure 7\r\nInconvenience for Having Meals According to the popular locations, we can know that restaurants were also the locations that the employees often drove to during the time for lunch and dinner. It means that employees could not have meals within GAStech or nearby GAStech, which caused inconvenience and time waste for employees.\r\nFigure 8\r\nOvertime Work Drinking coffee as breakfast or lunch is popular for GAStech employees, but the uncommon time of drinking coffee is likely to lead to overtime work. According to the frequency of purchase, Guy’s Gyros, Hippokampos, Katerina’s Caf were popular in 19:00-20:00, but coffee is not a wise choice to drink in the evening due to the probable insomnia problems. However, someone will drink coffee to keep the spirit in the evening in order to deal with their work. We can speculate overtime work is common for GAStech employees.\r\nFigure 9\r\n5.2.4 Recommendation\r\nGAStech should improve efficiency and arrange daytime reasonably to reduce overtime work and keep employees healthy.\r\nGAStech should provide more comfortable restaurants for employees within the area of company, which will be more convenient for employees to have their meals nearby instead of driving to have meals.\r\nFor some necessary overtime work, the company should provide comfortable working space in the evening.\r\n6. Owner Inference\r\n6.1 Plot GPS Path and Stop-by Points for Each Car\r\nUsing gps dataset, we can get maps of GPS paths and stop-by points for each car.\r\nFirstly, plot the map of Kronos and build the dataset of GPS path.\r\n\r\n\r\n# Import MC2-tourist.tif\r\nbgmap <- raster(\"MC2/MC2-tourist.tif\")\r\n\r\n# Tidy up dataset\r\ngps_final1 <- gps\r\n\r\ngps_final1$id <- as_factor(gps_final1$id)\r\ngps_final1$day <- as.factor(get_day(gps_final1$Timestamp))\r\n\r\ngps_sf <- st_as_sf(gps_final1,                   \r\n                   coords=c(\"long\",\"lat\"),\r\n                   crs=4326)\r\n\r\n# Build the dataset of GPS path\r\ngps_path <- gps_sf %>%\r\n  group_by(id,day) %>%\r\n  summarize(m=mean(Timestamp),\r\n             do_union=FALSE) %>%\r\n  st_cast(\"LINESTRING\")\r\n\r\n\r\n\r\nAnd then we should figure out the stop-by points. In this part, the stop-by points mean that the person stops the cars for a period larger than 300 seconds (5 minutes). Start time means the start time of stopping cars and end time means the end time of stopping cars (restart cars and move forward). Time different (tdiff) is calculated by End time-Start time, and the stops of cars with a period larger than 300 seconds will be selected.\r\n\r\n\r\n# Calculate and select rows with the time difference larger than 300 seconds\r\ngps_stop <- gps\r\n\r\ngps_stop <- gps_stop %>% \r\n  arrange(id,Timestamp)\r\n\r\ngps_stop$tdiff <- unlist(tapply(gps_stop$Timestamp, INDEX = gps_stop$id,\r\n                          FUN = function(x) c(0, `units<-`(diff(x),\"secs\"))))\r\n\r\ngps_stop <- gps_stop %>% \r\n  filter(tdiff>300) %>% \r\n  rename(endtime=Timestamp) %>% \r\n  mutate(starttime=endtime-tdiff)\r\n\r\ngps_stop_sf <- st_as_sf(gps_stop,                   \r\n                   coords=c(\"long\",\"lat\"),\r\n                   crs=4326)\r\n\r\n\r\n\r\nPlot the GPS path and stop-by points for each car, and we use the graph of the car whose ID is 1 as the example.\r\n\r\n\r\n# Set the tmap mode to \"view\"\r\ntmap_mode(\"view\")\r\n\r\n# Select the dataset for ID 1 car \r\ngps_stop_sf_selected <- gps_stop_sf %>%\r\n  filter(id==1)\r\ngps_path_selected <- gps_path %>%\r\n  filter(id==1)\r\n\r\n# Plot the map, GPS path and stop-by points\r\ntm_shape(bgmap) +\r\n  tm_rgb(bgmap, r = 1,g = 2,b = 3,\r\n       alpha = NA,\r\n       saturation = 1,\r\n       interpolate = TRUE,\r\n       max.value = 255) +\r\n  tm_shape(gps_stop_sf_selected) +\r\n  tm_dots(size = 0.075)+\r\n  tm_shape(gps_path_selected) +\r\n  tm_lines(col = \"day\",\r\n           lwd = 3)\r\n\r\n\r\npreserve7ba2dd96e9e83309\r\n\r\nCarID|Path Plots|CarID|Path Plots\r\n1||2|\r\nBased on the GPS path and stop-by points for each car, we can reassess the anomalies in 5.2.3. Coffee shops were indeed the popular locations due to frequent appears of stop-by points in coffee shops and someone would go to coffee shops in the evening after leaving the company (may work in coffee shops), as showing the following graph for car ID 6 in the date of 6.\r\n\r\n\r\n# Select the dataset for ID 6 car in the date of 6\r\ngps_stop_sf_selected_work <- gps_stop_sf %>%\r\n  filter(id==6,get_day(endtime)==6)\r\ngps_path_selected_work <- gps_path %>%\r\n  filter(id==6,day==6)\r\n\r\n# Plot the map, GPS path and stop-by points\r\ntm_shape(bgmap) +\r\n  tm_rgb(bgmap, r = 1,g = 2,b = 3,\r\n       alpha = NA,\r\n       saturation = 1,\r\n       interpolate = TRUE,\r\n       max.value = 255) +\r\n  tm_shape(gps_stop_sf_selected_work) +\r\n  tm_dots(size = 0.075)+\r\n  tm_shape(gps_path_selected_work) +\r\n  tm_lines(col = \"day\",\r\n           lwd = 3)\r\n\r\n\r\npreserve47dc5a00e3e9fc58\r\n\r\nAfter ID 6 car leaf GAStech at 17:30 at the date of 2012/1/6, the user of this car arrived Guy’s Gyros (coffee shops) at 18:45 and arrived Katerina’s Caf at 20:14. The user may work in these two coffee shops.\r\nFigure 10\r\n6.2 Match Owners for Credit Card and Loyalty Card\r\nAfter observing, we knew that there are some purchase records show the same purchase price, purchase locations and purchase date in the dataset for both credit card and loyalty card, so we can speculate that the purchse records were done at the same time by the same person. Hence, we can match credit cards and loyalty cards firstly and then figure out the owners of them.\r\n\r\n\r\n# Match cards by the same purchase price, purchase locations and purchase date\r\ncreditcard_final_day <- creditcard_final\r\ncreditcard_final_day$timestamp <- format(creditcard_final_day$timestamp,format=\"%Y-%m-%d\")\r\nloyaltycard_final_day <- loyaltycard_final\r\nloyaltycard_final_day$timestamp <- as.character(loyaltycard_final_day$timestamp)\r\nloyal_creidt <- inner_join(creditcard_final_day,loyaltycard_final_day,\r\n                          by=c(\"price\",\"location\",\"timestamp\")) %>% \r\n  select(last4ccnum,loyaltynum)\r\n\r\n# Build dataset for the result of matching\r\nloyal_creidt_unique <- unique(loyal_creidt) \r\nloyal_creidt_unique <- loyal_creidt_unique%>% \r\n  group_by(last4ccnum) %>%\r\n  summarise(loyaltynum = paste(loyaltynum, collapse = \", \"))\r\n\r\n\r\n\r\n\r\n\r\n# Transforming data\r\ncreditcard_final_net <- creditcard_final\r\n\r\ncreditcard_final_net$last4ccnum <- as.character(creditcard_final_net$last4ccnum)\r\ncreditcard_final_net$Day  <-  get_day(creditcard_final_net$timestamp)\r\ncreditcard_final_net$Hour <-  get_hour(creditcard_final_net$timestamp)\r\n\r\n# Creating nodes list\r\nsources <- creditcard_final_net %>%\r\n  distinct(last4ccnum) %>%\r\n  rename(label = last4ccnum)\r\ndestinations <- creditcard_final_net %>%\r\n  distinct(location) %>%\r\n  rename(label = location)\r\ncc_nodes <- full_join(sources, \r\n                   destinations, \r\n                   by = \"label\")\r\ncc_nodes <- cc_nodes %>% \r\n  rowid_to_column(\"id\")\r\n\r\n# Creating and tidying edges list\r\nedges <- creditcard_final_net %>%  \r\n  group_by(last4ccnum, location, Day, Hour) %>%\r\n  summarise(weight = n()) %>% \r\n  ungroup()\r\n\r\ncc_edges <- edges %>% \r\n  left_join(cc_nodes, \r\n            by = c(\"last4ccnum\" = \"label\")) %>% \r\n  rename(from = id)\r\n\r\ncc_edges <- cc_edges %>% \r\n  left_join(cc_nodes, \r\n            by = c(\"location\" = \"label\")) %>% \r\n  rename(to = id)\r\n\r\ncc_edges <- select(cc_edges, from, to, \r\n                   Day, Hour, weight)\r\n\r\ncc_graph <- tbl_graph(nodes = cc_nodes, \r\n                      edges = cc_edges, \r\n                      directed = FALSE)\r\n\r\nvisNetwork(cc_nodes,\r\n           cc_edges) %>%\r\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\r\n  visOptions(highlightNearest = TRUE,\r\n             nodesIdSelection = TRUE) %>%\r\n  visLegend() %>%\r\n  visLayout(randomSeed = 123)\r\n\r\n\r\npreservea2c72ad291a88581\r\n\r\n\r\n\r\ncreditcard_final_loyalty_DT <- creditcard_final %>% \r\n  group_by(last4ccnum,location) %>% \r\n  summarise(purchasenum=n())\r\ncreditcard_final_loyalty_DT <- left_join(creditcard_final_loyalty_DT,\r\n                                           loyal_creidt_unique,\r\n                                           by=\"last4ccnum\")\r\ncreditcard_final_loyalty_DT <- creditcard_final_loyalty_DT %>% \r\n  arrange(desc(purchasenum))\r\n\r\n# Build DT\r\nDT::datatable(creditcard_final_loyalty_DT)\r\n\r\n\r\npreservef3ebeb9f8a88f7d1\r\n\r\n\r\n\r\ngps_stop_1200 <- gps_stop %>% \r\n  filter(tdiff>1200)\r\n\r\ngps_stop_1200$cc_purchase <- \"\"\r\n\r\ngps_stop_1200 <- gps_stop_1200 %>% \r\n  filter(id==1)\r\n\r\ncreditcard_final_loyalty <- left_join(creditcard_final,\r\n                                     loyal_creidt_unique,\r\n                                     by=\"last4ccnum\")\r\n\r\nwithin<-function(time,starttime,endtime,ccnum){\r\n  if (starttime<time&time<endtime)\r\n    return(ccnum)\r\n}\r\n\r\n#for (i in 1:1490){\r\n  #  for (j in 1:87){\r\n   #   a <- within(creditcard_final_loyalty[i,1],\r\n    #              gps_stop_1200[j,6],\r\n    #              gps_stop_1200[j,1],\r\n    #              creditcard_final_loyalty[i,4])\r\n    #  gps_stop_1200[j,7] <- paste(gps_stop_1200[j,7],as.character(a),sep = \" \")\r\n   #   a <- \"\"\r\n #   }\r\n#}\r\n\r\n\r\n\r\n6.3 Uncertainties\r\n7. Anomalies and Suspicious Activity\r\n7.1 Evidence\r\n7.2 Location Identification\r\n8. Conclusion\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-07-05-assignment/assignment_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-07-25T00:24:40+08:00",
    "input_file": "assignment.knit.md"
  },
  {
    "path": "posts/2021-06-13-dataviz-makeover-2/",
    "title": "Dataviz Makeover 2",
    "description": "This post is built for DataViz Makeover 2 of ISSS608 Visual Analytics and    Application.",
    "author": [
      {
        "name": "LI Yuhong",
        "url": {}
      }
    ],
    "date": "2021-06-13",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Introduction\r\n1.1 Data Source\r\n1.2 The Original Visualisation\r\n\r\n2. Critiques and Suggestions\r\n2.1 Clarity\r\n2.2 Aesthetics\r\n\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\n3.2 Advantages of Proposed Design\r\n\r\n4. Data Visualisation Steps\r\n4.1 Data Preparation\r\n4.2 Import and Pivot Data\r\n4.3 Data Visualisation\r\n4.4 Final Visualisation\r\n\r\n5. Main Observations\r\n\r\n1. Introduction\r\n1.1 Data Source\r\nThe data visualisations, including the original one and the redesigned one, were created by using data provided by Department of Statistics, Singapore (DOS). The data are available under the sub-section of Merchandise Trade by Region/Market and are compiled by the Enterprise Singapore.\r\n1.2 The Original Visualisation\r\nThe original data visualisation that will be assessed was shown in the following figure. This visualization shows the merchandise trade, including export and import, between Singapore and top six trading countries during the period from January 2011 to December 2020.\r\nFigure 1\r\n2. Critiques and Suggestions\r\n2.1 Clarity\r\nS/N\r\nCritiques\r\nComments\r\n1\r\nThere is not a title: The lack of a title prevents the readers from quickly understanding the purpose of the visualisation. There are two notes for describing the information of this graph, but the long description is not so direct as a concise title.\r\nAdd a concise title, like “Singapore’s Merchandise Trade Value with Ten Trading Partners, 2011-2020”.\r\n2\r\nThe lack of unit for x-axis and y-axis: There are a series of numbers in x-axis and y-axis to show the values of exports and imports respectively, but there is not a label to show the unit of x-axis and y-axis.\r\nAdd the unit label of SGD in billion, “S$(Billion)” for x-axis and y-axis.\r\n3\r\nThe positions of titles for x-axis and y-axis are misleading: Although the colors and icons can help readers to distinguish which axis is for import value and which axis is for export value, the unreasonable positions (at the beginning of each axis) of “Exports” and “Imports” for x-axis and y-axis are still very confusing.\r\nPut the titles in the middle position of each axis.\r\n4\r\nThere is not information about the study period: We can’t know the study period of this visualisation.\r\nAdd the period of “2011-2020” in the main title or add a note to show the period, “between January 2011-December 2020”.\r\n5\r\nIt is difficult to distinguish the import value and export value for each region: Because there are a large amount of overlap parts among some bubbles or some centre points were covered by the labels of total trade value, we can’t see all the centre points in the graph clearly. The hidden centre points prevent readers from knowing the import value and export value.\r\nMake the size of each bubble smaller to show all the cretre points and move the positions of some labels.\r\n6\r\nThe icons of “TOP NET EXPORTER” and “TOP NET IMPORTER” are confusing: When readers firstly see the icons of “TOP NET EXPORTER” and “TOP NET IMPORTER” in the graph, it is difficult for readers to know the meanings of the icons until they see the legends below. It is an indirect description.\r\nChange the icons in the graph to texts of “TOP NET EXPORTER” and “TOP NET IMPORTER” and then remove the legend below.\r\n2.2 Aesthetics\r\nS/N\r\nCritiques\r\nComments\r\n1\r\nThe unreasonable layouts of the graph, the legend and notes: The readers will be more easy to see the legend if the legend is closed to the graph part. However, positions of legends, “TOP NET EXPORTER” and “TOP NET IMPORTER”, are below the note in this graph, the position is abnormal.At the same time, the abnormal layout causes the whole visualisation chaotic.\r\nPut the legend on the left of the graph or above the note part.\r\n2\r\nToo large size of the bubbles: Because there are some overlap part of bubbles due to the too large size, we can not see all the bubbles completely. Too large bubbles do not only cause difficulties in transferring information of the graph, but also cause the mussy layout.\r\nMake the size of bubbles smaller.\r\n3\r\nToo many different fonts are used in this graph: There are three different fonts are used in the part of graph, note and information description respectively. The inconsistent fonts will cause the all visualisation no so beautiful and professional.\r\nUse the same font in the part of note and information description.\r\n4\r\nThe background color of information description part is too dark: The blue background color is more dark than other parts of this visualisation, so when readers see this visualisation, their attention will be caught by this part. The most important part, graph part, may not be focused on during readers’ first reading.\r\nRemove the background color of the information description part and change the font color to black as the font in note part.\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\nFigure 2\r\n3.2 Advantages of Proposed Design\r\nClear and interactive title: The main title “Merchandise Trade Change and Comparison of Trading Partners, 2011-2020” shows the purpose of the visulisation and subtitles provide interactive parts of “(Period)” which will change as the reader’s choice.\r\nSuitable size of the bubbles: Adjust the size of bubbles in order to decrease the overlap area and show the bubble of each trading partner clearly.\r\nSimple and clear layout: Delete the unnecessary part of the visualisation,like the information part at the bottom of the visualisation and adjust the layout of the visualisation.\r\nThe use of interactive techniques: Add interactive techniques to give the reader more freedom to read the images. For example, the readers can change the year and trading partners they want to know by using the function of filter.\r\n4. Data Visualisation Steps\r\n4.1 Data Preparation\r\nDownload the dataset from the website of Department of Statistics, Singapore(DOS), and then open the file by Excel.Delete the unnecessary sheet of “Content” and then rename the sheets of “T1” and “T2” as “Import” and “Export”.\r\nFigure 3\r\nSelect the useless rows from 1 to 5 and from 100 to 112 in sheets of both “Import” and “Export”, and then delete these selected rows.\r\nFigure 4\r\nSelect the columns that are not in the study period, and then delete them in sheets of both “Import” and “Export”.\r\nFigure 5\r\nWe will not use the data of continents and “Total Merchandise Imports”, so the rows from 2 to 8 were seleced and deleted.\r\nFigure 6\r\nAfter observing the values of dataset, we find that the unit for the dataset is “Thousand Dollars”, so we should adjust the value. Enter “1000” in any empty cell, and copy it. Select the value part , and then right click to choose “Paste Special”. Under the function of Operation, the “Multiply” choice was selected, and then we clicked “OK”. Do the same actions in both sheets, and clear the cell of “1000” after completing the above actions.\r\nFigure 7\r\nAll the “Thousand Dollars” were replaced by empty by the function of Replace.\r\nFigure 8\r\nAt last, save the file, “outputFile”.\r\n4.2 Import and Pivot Data\r\nImport the file of “outputFile” into Tableau. And drag “Import” into the pane.\r\nFigure 9\r\nSelect all the columns except the first column, and then right click to choose “Pivot”.\r\nFigure 10\r\nRename the pivoted columns to “Period” and “Imports” respectively, and change the data type of “Period” column to Date.\r\nFigure 11\r\nDo the similar actions in the sheet of “Export”, but rename the pivoted columns to “Period (Export)” and “Exports” respectively. Combine the sheet of “Import” and “Export” by the Region and Period value as figure 12.\r\nFigure 12\r\n4.3 Data Visualisation\r\nClick Analysis->Create Calculated Field, and then create a new variable of “Total Trade”. The formula of “Total Trade” is shown in the Figure 13.\r\nFigure 13\r\nDrag the variables as Figure 14. And change the chart type to Circle.\r\nFigure 14\r\nEdit the title of chart as Figure 15.\r\nFigure 15\r\nClick Analysis->Create Calculated Field, and then create a new variable of “Reference Line”. The formula of “Total Trade” is shown in the Figure 16.\r\nFigure 16\r\nDrag “Reference Line” to Rows.\r\nFigure 17\r\nChange the chart type to Line, and adjust the color opacity to 0. And then add the trend line by right click.\r\nFigure 18\r\nRight click the “Reference Line” to choose dual axis. And then we got the following result. Right click the axis of Reference Line and show header.\r\nFigure 19\r\nAdjust the Format of all the values as the following figures. The similar setting method will be used in other charts.\r\nFigure 20\r\nFigure 21\r\nAdd the Labels of countries and values.\r\nFigure 22\r\nCheck “Show history”. Rename the worksheet as “Bubble Chart”.\r\nFigure 23\r\nCreate a new worksheet and then drag the variables as Figure 24 and then change the size of the whole chart. Add highlighters under Analysis->Highlighters->Measure Name. Rename the worksheet as “Trade Value”.\r\nFigure 24\r\nCome back to the worksheet of “Bubble Chart”, and then click the Tooltip button. Click Insert and then add the chart in worksheet “Trade Value” as Figure 25. When we put the cursor in a bubble, we will see the Tooptip shown as Figure26.\r\nFigure 25 Figure 26\r\nCreate a new worksheet and then rename it as “Value Comparison”. Drag the variables as Figure 27. Change the title as “Comparison of Imports and Exports among Regions, ” by using title edit.\r\nFigure 27\r\nCreate a dashboard and rename it as “Merchandise Trade”. Drag and adjust the worksheet as Figure 28. Add the main title of “Merchandise Trade Change and Comparison of Trading Partners, 2011-2020”, and add the note.\r\nFigure 28\r\nRight click in the area of Region filter, and then check “All Using Related Data Sources”.\r\nFigure 29\r\nThe whole chart will change when checking different regions and different years.\r\nFigure 30\r\n4.4 Final Visualisation\r\nThe snapshot of dashboard is shown in the following and then rename the dashboard to “Merchandise Trade”.\r\nFigure 31\r\n5. Main Observations\r\n1) The change of trade roles within the given period: Based on the change track of bubbles shown in the visualisation, we can know that the trade roles of most trading partners did not change during the study period, which means that most trading partners kept the roles of net exporters or net importers in this 10 years. However, there are still some changes of trade roles for some trading partners. For example, United State changed from net importers to net exporters from 2019 to 2020 while Malaysia changed from net exporters to net importers from 2018 to 2019.\r\nFigure 32\r\nFigure 33\r\n2) Imbalance merchandise trade value among trading partners: The position and size of bubbles show that most of the trading partners show relatively small trade values, and they are clustered in the lower left corner of the picture. The top 10 trading partners do far more trade than most other countries, both in terms of exports and imports. These large trading partners tend to be more developed or more populous economies.\r\nFigure 34\r\n3) Hong Kong and Taiwan are special trading partners for Singapore: During the given 10 years, the positions of most trading partners, especially the large trading partners, were closed to the diagonal reference line, which means that the difference between exports and imports is not so large for most trading partners. However, the positions of Hong Kong and Taiwan are far from the diagonal reference line. This means that Hong Kong is a net exporters with relative larger trade surplus value while Taiwan is a net importers with relative relative larger trade deficit value.\r\nFigure 35\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-06-21T16:18:29+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-30-dataviz-makeover-1/",
    "title": "DataViz Makeover 1",
    "description": "This post is built for DataViz Makeover 1 of ISSS608 Visual Analytics and    Application.",
    "author": [
      {
        "name": "LI Yuhong",
        "url": {}
      }
    ],
    "date": "2021-05-30",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Introduction\r\n1.1 Data Source\r\n1.2 The Original Visualisation\r\n\r\n2. Critiques and Suggestions\r\n2.1 Clarity\r\n2.2 Aesthetics\r\n\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\n3.2 Advantages of Proposed Design\r\n\r\n4. Data Visualisation Steps\r\n4.1 Data Preparation\r\n4.2 Import and Pivot Data\r\n4.3 Data Visualisation\r\n4.4 Final Visualisation\r\n\r\n5. Main Observations\r\n\r\n1. Introduction\r\n1.1 Data Source\r\nThe data visualisations, including the original one and the redesigned one, were created by using data provided by Department of Statistics, Singapore (DOS). The data are available under the sub-section of Merchandise Trade by Region/Market and are compiled by the Enterprise Singapore.\r\n1.2 The Original Visualisation\r\nThe original data visualisation that will be assessed was shown in the following figure. This visualization shows the merchandise trade, including export and import, between Singapore and top six trading countries during the period from 2019 to 2020. Based on this visualisation, we should not only compare the quantity of merchandise trade among these six countries, but also compare the difference between export and import in each graph.\r\nFigure 1\r\n2. Critiques and Suggestions\r\n2.1 Clarity\r\nS/N\r\nCritiques\r\nComments\r\n1\r\nChart title is not precise: The title “Merchandise Trade of Top Six Trading Countries, 2019-2020” does not derive the explicit information of the merchandise trade, which means that we cannot know the merchandise trade is the quantity of export and import between Singapore and other six countries.\r\nChange the title to “Singapore’s Merchandise Trade (Export, Import and Trade Balance) of Top Six Trading Countries, 2019-2020”.\r\n2\r\nThere are not clear notes for the chart”: The necessary notes were lost, so we cannot know the currency unit and data source of this chart.\r\nAdd clear notes to describe necessary concepts and information.\r\n3\r\nX axis title and tick marks were not properly labeled: The title of x axis is “Month of Period”, but the tick marks show the years which don’t match the title properly.\r\nChange the title of x axis to “Time”.\r\n4\r\nDifferent ranges of y axis for import and export makes the comparison difficult: Within the graph for a country, it is difficult for readers to compare the import and export based on different ranges, which means that readers cannot know whether export is larger than import or not intuitively. At the same time, due to the different ranges of y axis among different graphs, we cannot compare the trade volume among countries directly.\r\nFix all the ranges of y axis consistent.\r\n5\r\nThe lack of labels in x axis: In the graph of Japan, there are not labels for the year of 2019 and 2021 in x axis.\r\nAdd the lacking labels in x axis.\r\n6\r\nUnclear aim of the chart: There is not a very clear goal to show in this chart, which means that the reader does not know whether the graph is comparing imports and exports of each country or among countries.\r\nShow clear aim in the chart title or choose proper chart type.\r\n7\r\nThe lack of unit: There is not a unit note or label of the values.\r\nAdd a unit note or label.\r\n2.2 Aesthetics\r\nS/N\r\nCritiques\r\nComments\r\n8\r\nThe title’s font size: The font size of chart title is not so large compared with other characters in the chart, so the readers cannot realize the title easily. It will be more reasonable to make the title’s font size bigger.\r\nMake the title’s font size bigger.\r\n9\r\nThe width of each graph is not the same: The six graphs for each country showed the same period from 2019 to 2020, but the width is not the same in each graph. The uneven width can be confusing to the readers.\r\nFix the width of each graph consistent.\r\n10\r\nThe inappropriate chart type: The overlap of import area and export area makes the graphs confusing and messy. It is difficult for readers to follow the edges of export or import area within the part of overlap, so readers cannot get information quickly and clearly. And the dark color of overlap areas makes the graphs messy.\r\nAdjust the color of overlap area and change the graphs to line charts.\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\nFigure 2\r\n3.2 Advantages of Proposed Design\r\nClear title: shows Singapore’s merchandise trade of Top Six Trading Countries in the period from 2019 to 2020.\r\nShort and clear note: figures out the, data source, currency unit and definition of “Trade Balance”.\r\nAxis are properly labeled: shows the clear axis labels and consistent tick marks. Consistent tick marks are convenient for readers to compare among countries intuitively.\r\nMore suitable chart types: the line charts are used to show the changes of export and import in the given period. At the same time, this line graph shows a third line of trade balance which is an important value in researching merchandise trade.\r\nColors: are consistent, clear and suitable.\r\n4. Data Visualisation Steps\r\n4.1 Data Preparation\r\nDelete unnecessary worksheet and rename worksheets: Delete the “Content” worksheet and rename “T1” and “T2” to “Import” and “Export” respectively.\r\nFigure 3\r\nFigure 4\r\nRemove unnecessary columns: Only the data from 2019 to 2020 will be used, so the columns of other years should be removed from the worksheets of Import and Export.\r\nFigure 5\r\nRemove unnecessary rows: Only the data of Hong Kong, Mainland China, Japan, Malaysia, Taiwan and US will be used, so the introduction of the dataset and the data of other countries should be removed from the worksheets of Import and Export.\r\nFigure 6\r\nTranspose the data: The time is shown in the first row while the countries are shown in the first column, but we need to exchange the place of time and countries. Select and copy the area of dataset, and then right click in empty space to choose Transpose under the function of Paste Option. After pasting the data, the original data should be deleted and the dataset is shown as following. Complete this step in two worksheets.\r\nFighre 7\r\nRename the headers: Change the headers of “Variables” to “Date” and complete similar step in the worksheet of Export.\r\nFighre 8\r\nFigure 9\r\nCreate new worksheets for each country: Create a new worksheet called “Malaysia”, and then copy the date, Malaysia’ Import column and Malaysia’ Export column in this new worksheet. Add a new column of “Trade Balance” and then calculate the value of it by “Export”-“Import”. Using the similar steps, the new worksheets for other countries were created.\r\nFigure 10\r\nSave and rename the Excel file: Change the File name of Excel to “Merchandise Trade” and then save it.\r\nFigure 11\r\n4.2 Import and Pivot Data\r\nImport the file of “Merchandise Trade” into Tableau. And then drag the table “Hong Kong” into table area.\r\nFigure 12\r\nCombine all the other countries based on “Date”.\r\nFigure 13\r\nSelect the columns of “Import”, “Export” and “Trade Balance” and then right click to pivot these data. Change the data type of column “Date” to Date, and change the data type of column “Pivot Field Values” to *Number(whole).\r\nFigure 14\r\nChange the name of “Pivot Field Names” to “Type” and change the name of “Pivot Field Values” to “Value”.\r\nFigure 15\r\nRepeat the steps above in the tables of other countries.\r\n4.3 Data Visualisation\r\nChange the name of sheet 1 and the title to “Hong Kong”. In this sheet, drag “Date (Hong Kong)” and “Value (Hong Kong)” into Columns and Rows respectively. Change the data type of “Date” to Month. And then drag “Type” to Colour under the function card of Marks. The line chart will be created as the following figure.\r\nFigure 16\r\nSetting the same range of y axis is convenient for comparing among different graphs. After observing the range of all the charts, we knew that the range of y axis that suits all charts is from -3,000,000 to 8,000,000, so we should change the range of y axis in these six graphs. Edit Axis as the following figure.\r\nFigure 17\r\nAdd a reference line at the constant value of 0, and then adjust the reference line as the following figure in all the six graphs. The reference line can help readers to figure out whether the result of trade balance is surplus or deficit.\r\nFigure 18\r\nBased on the original dataset, we knew that the currency used to measure is US dollar, so we should apply currency of US dollar in the units of graphs. Edit the units of “Value” by the steps shown in following figures and do the same steps for all graphs.\r\nFigure 19\r\nFigure 20\r\nBy using the same manipulation in the sheet of “Hong Kong”, the worksheets of other countries were built.\r\nFigure 21\r\n4.4 Final Visualisation\r\nAfter building a new dashboard, add all the six graphs in it and adjust the position of graphs. Click “Show dashboard title”, and then edit the tile to “Singapore’s Merchandise Trade (Export, Import and Trade Balance) of Top Six Trading Countries, 2019-2020”. Adjust the position and the font size for the title and subtitles.\r\nFigure 22\r\nEdit board for each sub-graph.\r\nFigure 23\r\nDelete redundant legends and rename the legend as the following.\r\nFigure 24\r\nThe snapshot of dashboard is shown in the following and then rename the dashboard to “Merchandise Trade”.\r\nFigure 25\r\n5. Main Observations\r\n1) Trade Scale of Import and Export\r\nWithin these six counties, Singapore had larger export value with Hong Kong, Mainland China, Malaysia and United State, while had relatively lower export value with Japan and Taiwan. Import values showed that Singapore had larger import value with Mainland China, Malaysia, Taiwan and United State, but had smaller value with Japan and Hong Kong. Totally, Japan had the smallest scale of trade with Singapore due to the lower value of both import and export.\r\n2) Fluctuation\r\nChina and the United States had larger fluctuations in all the three values (import, export and trade balance) than other countries. There were some fluctuations in Hong Kong but the values kept totally stable. Japan and Taiwan showed pretty flat fluctuations during the given period. There seemed a significant decline in Hong Kong’ import and export, Mainland China’s import and export, Malaysia’ import and export, United State’ import at the similar period of the beginning of 2020. For the trade between Singapore and Malaysia, there was an obvious decline in the values of import and export at the beginning of 2020, and after that trade balance kept in negative value (trade deficit).\r\n3) Trade Balance\r\nMost countries showed relatively approximate values of import and export, but there was a pretty difference between export value and import value for Taiwan, especially Hong Kong. Based on the chart, we can know that Hong Kong showed the largest scale of trade surplus (the highest positive value in trade balance) and Taiwan showed the scale of trade deficit (the lowest negative value in trade balance) in the international trade with Singapore.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-06-16T17:02:27+08:00",
    "input_file": {}
  }
]
